task: "train"

dataset_name: "svamp"

model_name_or_path: "../models/Llama-3.2-1B-Instruct"
adapter_name: "gsm8k"
output_dir: "./test-output"

local_dataset_dir: "../lora-merging-datasets/"
subsample: 1000
disable_dataset_cache: true
dataset_num_proc: 1

logging_steps: 100
save_strategy: "no"

max_seq_length: 2048
disable_seq_length_filter: false
num_train_epochs: 2

per_device_train_batch_size: 2
gradient_accumulation_steps: 1

use_peft_lora: true
lora_r: 16
lora_alpha: 64
lora_dropout: 0.05
lora_target_modules: "q_proj,v_proj"

use_flash_attn: true
gradient_checkpointing: false
use_reentrant: false

fp16: false
bf16: true
use_4bit_quantization: true
bnb_4bit_compute_dtype: "bfloat16"

report_to: "none"