"""
# Author: Yinghao Li
# Modified: March 19th, 2025
# ---------------------------------------
# Description:

This module splits the original TokenAttributes functionality into:
1) TokenAttributesData: a dataclass to store attributes.
2) TokenAttributesProcessor: a class containing all methods for processing
   the attention matrices and hidden states generated by a transformer model.
"""

import logging
import os.path as osp
import numpy as np
import torch
import gc
from dataclasses import dataclass, field
from seqlbtoolkit.io import ProgressBar
from seqlbtoolkit.training.dataset import unpack_instances

from src.utils.io import load_attrs, save_attrs

logger = logging.getLogger(__name__)


@dataclass
class TokenAttributes:
    """
    Holds all the token-related attributes (IDs, probabilities, attention, etc.).
    Also includes methods for loading from disk/memory, saving processed results,
    and freeing GPU memory.
    """

    # Basic data
    instance_ids: list[str] = field(default_factory=list)
    tkresp_int_list: list[list[int]] = field(default_factory=list)
    top5_tkresp_int_list: list[list[int]] = field(default_factory=list)
    top5_tkresp_prob_list: list[np.ndarray] = field(default_factory=list)

    # Auxiliary info for processing, including attention matrices, entropies, hidden states
    attn_mats_list: list[np.ndarray] = field(default_factory=list)
    attn_entropy_list: list[np.ndarray] = field(default_factory=list)
    output_logits_list: list[np.ndarray] = field(default_factory=list)

    # Processed results (chains, scores, similarity)
    tkattn_srcidx_list: list[np.ndarray] = field(default_factory=list)
    tkattn_scores_list: list[np.ndarray] = field(default_factory=list)
    tkattn_to_tkans_sims_list: list[np.ndarray] = field(default_factory=list)
    tkans_srcidx_list: list[np.ndarray] = field(default_factory=list)

    def __len__(self):
        return len(self.instance_ids)

    def __add__(self, other):
        if not isinstance(other, TokenAttributes):
            raise ValueError(f"Unsupported addition with type: {type(other)}")

        self.check_equal_lengths()
        other.check_equal_lengths()

        new_instance = TokenAttributes()
        for attr in self.keys():
            setattr(new_instance, attr, getattr(self, attr) + getattr(other, attr))

        return new_instance

    def __radd__(self, other):
        return self.__add__(other)

    def __iadd__(self, other):
        if not isinstance(other, TokenAttributes):
            raise ValueError(f"Unsupported addition with type: {type(other)}")

        self.check_equal_lengths()
        other.check_equal_lengths()

        for attr in self.keys():
            setattr(self, attr, getattr(self, attr) + getattr(other, attr))

        return self

    def to(self, device: torch.device):
        """
        Move all tensors to the specified device.
        """
        for attr in self.keys():
            try:
                setattr(self, attr, [t.to(device) for t in getattr(self, attr)])
            except AttributeError:
                pass
        return self

    def __getitem__(self, idx: int | str):
        """
        Overload to allow easy dictionary-style or index-based access.
        """
        if isinstance(idx, str):
            if idx in self.keys():
                return getattr(self, idx)
            raise KeyError(f"Undefined key: {idx}")

        return (
            self.instance_ids[idx],
            self.tkresp_int_list[idx],
            self.top5_tkresp_int_list[idx],
            self.top5_tkresp_prob_list[idx],
            self.tkattn_srcidx_list[idx],
            self.tkattn_scores_list[idx],
            self.tkattn_to_tkans_sims_list[idx],
            self.tkans_srcidx_list[idx],
        )

    def keys(self):
        """
        list the "primary" attributes likely to be examined or stored.
        """
        return (
            "instance_ids",
            "tkresp_int_list",
            "top5_tkresp_int_list",
            "top5_tkresp_prob_list",
            "tkattn_srcidx_list",
            "tkattn_scores_list",
            "tkattn_to_tkans_sims_list",
            "tkans_srcidx_list",
        )

    def retrieve_mandatory_attributes(self, include_hidden_states: bool = False):
        """
        Return a list of attributes that must match in length across all data fields.
        When keep_hidden_states is True, we also track attention/hidden states.
        """
        attrs = [
            "instance_ids",
            "tkresp_int_list",
            "top5_tkresp_int_list",
            "top5_tkresp_prob_list",
        ]
        if include_hidden_states:
            attrs.append("attn_mats_list")
            attrs.append("output_logits_list")
            if self.attn_entropy_list:
                attrs.append("attn_entropy_list")
        return attrs

    def check_equal_lengths(self, keep_hidden_states: bool = False):
        """
        Ensure all essential attributes match in length.
        """
        length = len(self)
        for attr in self.retrieve_mandatory_attributes(include_hidden_states=keep_hidden_states):
            attr_len = len(getattr(self, attr))
            if attr_len != length:
                raise ValueError(f"Length mismatch for attribute '{attr}'. " f"Expected {length}, got {attr_len}")
        return True

    # ---------------------
    # Loading, Saving, and Free operations
    # ---------------------

    def load(
        self,
        file_dir: str,
        file_name: str = "attrs.h5",
        instance_ids: str | list[str] = None,
        keys: list[str] = None,
        **kwargs,
    ):
        """
        Load data from disk into this dataclass.
        """
        if isinstance(instance_ids, str):
            instance_ids = [instance_ids]

        if not keys:
            generation_attributes = load_attrs(file_dir, file_name, instance_ids, **kwargs)
        else:
            generation_attributes = load_attrs(file_dir, file_name, instance_ids, keys=keys, **kwargs)

        self.instance_ids = list(generation_attributes.keys())
        (
            self.tkresp_int_list,
            self.top5_tkresp_int_list,
            self.top5_tkresp_prob_list,
            self.tkattn_srcidx_list,
            self.tkattn_scores_list,
            self.tkattn_to_tkans_sims_list,
            self.tkans_srcidx_list,
        ) = unpack_instances(
            instance_list=generation_attributes.values(),
            attr_names=[
                "tkresp_int",
                "top5_tkresp_int",
                "top5_tkresp_prob",
                "tkattn_srcidx",
                "tkattn_scores",
                "tkattn_to_tkans_sims",
                "tkans_srcidx",
            ],
        )

        return self

    def save(self, file_dir: str, file_name: str = "attrs.h5", metadata=None, disable_progress_bar: bool = False):
        """
        Save computed attention chains (and associated scores, similarities) to disk.
        """
        inst_len = len(self)
        if not self.tkattn_srcidx_list or not self.tkattn_scores_list or not self.tkattn_to_tkans_sims_list:
            raise ValueError("Attributes missing for saving attention chains.")
        if not (
            len(self.tkattn_srcidx_list) == inst_len
            and len(self.tkattn_scores_list) == inst_len
            and len(self.tkattn_to_tkans_sims_list) == inst_len
        ):
            raise ValueError("Length mismatch between chains and instances.")

        if not metadata:
            metadata = {}

        pbar = ProgressBar(total=inst_len, transient=True, desc="Save Attention Chains", disable=disable_progress_bar)
        with pbar:
            for i in range(len(self)):
                idx = self.instance_ids[i]

                attr_dict = {
                    "file_path": osp.join(file_dir, idx, file_name),
                    "tkresp_int": self.tkresp_int_list[i],
                    "top5_tkresp_int": self.top5_tkresp_int_list[i],
                    "top5_tkresp_prob": self.top5_tkresp_prob_list[i],
                    "tkattn_srcidx": self.tkattn_srcidx_list[i],
                    "tkattn_scores": self.tkattn_scores_list[i],
                    "tkattn_to_tkans_sims": self.tkattn_to_tkans_sims_list[i],
                    "tkans_srcidx": self.tkans_srcidx_list[i],
                    "metadata": metadata,  # Optional additional info
                }
                save_attrs(attr_dict)
                pbar.update()

    def free_loaded_hidden_states(self):
        """
        Free the attention hidden states from GPU memory (if applicable).
        """
        self.attn_mats_list = []
        self.attn_entropy_list = []
        self.output_logits_list = []
        torch.cuda.empty_cache()
        gc.collect()

        logger.warning("Attention and hidden state matrices are removed from memory.")

    def clear(self):
        """
        Clear all data fields.
        """
        for attr in self.keys():
            setattr(self, attr, list())
        return self
